{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756e4228-615d-44ee-92bb-3a3539d4b1de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Momentum Strategies based on Jegadeesh and Titman 1993 \"Returns to buying Winners and selling Losers: Implications for Stock Market Efficiency\"\n",
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02736e16-72e3-4601-b4b5-ca9a64a1d0f0",
   "metadata": {},
   "source": [
    "**<i>Program designed and executed by  Aryan Ayyar and  Dr. Abhishek Rohit under the guidance of Dr. Madhu Veeraraghavan and Dr Kavitha Ranganathan**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdda9b8-050a-4a64-ab45-c9b44789f4fa",
   "metadata": {},
   "source": [
    "## Data Import and Filtering -> Select the database and apply required filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf74e682-33d8-401f-bcb5-02bfca887205",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Our program is based on WRDS Python Momentum code and can be found at <a href=\"https://wrds-www.wharton.upenn.edu/documents/1442/wrds_momentum_demo.html\" target=\"_blank\">this link</a>. The program is decided to mimick the overlapping portfolio construction used by Narasimhan Jegadeesh and Sheridan Titman as well as incorporates liquidity factors from Lee and Swaminathan (2001).As quoted in the 1993 paper \"To increase the power of our tests, the strategies we examine include\n",
    "portfolios with overlapping holding periods. Therefore, in any given month t,\n",
    "the strategies hold a series of portfolios that are selected in the current\n",
    "month as well as in the previous K - 1 months, where K is the holding\n",
    "period. Specifically, a strategy that selects stocks on the basis of returns over\n",
    "the past J months and holds them for K months (we will refer to this as a\n",
    "J-month/K-month\n",
    "strategy) is constructed as follows: At the beginning of\n",
    "each month t the securities are ranked in ascending order on the basis of\n",
    "their returns in the past J months. Based on these rankings, ten decile\n",
    "portfolios (or quintiles or baskets as deemed fit according to the number of stocks) are formed that equally weight the stocks contained in the top\n",
    "decile, the second decile, and so on. The top decile portfolio is called the\n",
    "\"losers\" decile and the bottom decile is called the \"winners\" decile. In each\n",
    "month t, the strategy buys the winner portfolio and sells the loser portfolio,\n",
    "holding this position for K months. In addition, the strategy closes out the\n",
    "position initiated in month t - K. Hence, under this trading strategy we\n",
    "1\n",
    "revise the weights on - of the securities in the entire portfolio in any given\n",
    "month and carry over the rest from the previous month.\".<i> * Please note that in Jegadeesh and Titman, the W-L portfolio is P10-P1 and not P1-P10, the wordings as quoted in the paper may be misleading </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "96647424-7d60-4d6c-88a2-ed62bd6d6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary files and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy import stats\n",
    "from pandas.tseries.offsets import *\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "ex=\"andy\"\n",
    "#Use stocks only is Bombay Stock Exchange not present in National Stock Exchange\n",
    "bse_only= False\n",
    "\n",
    "#Liquidity decile as factored by Lee and Swaminathan-> \"liquid\",\"illiquid\",\"None\"\n",
    "liquidity= None\n",
    "#Make appropriate deciles and basked (3-10)\n",
    "basket=10\n",
    "decile=10\n",
    "\n",
    "#Split into deciles based on Market Cap\n",
    "market_decile=False\n",
    "subsample= False\n",
    "sampend=False\n",
    "\n",
    "bottom =True\n",
    "bottom_only=False\n",
    "q=0.05\n",
    "\n",
    "winsorize_turn=False\n",
    "winsorize_ret=False\n",
    "level=0.01\n",
    "\n",
    "penny_rem=False\n",
    "penny=1\n",
    "\n",
    "rem_fin=True\n",
    "rem_govt=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5ea6fc3b-30c0-40be-92a8-89a2a6806fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryan-intern23\\AppData\\Local\\Temp\\5\\ipykernel_7136\\3277890696.py:10: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  crsp=pd.read_csv(andy, usecols=['permno', 'Date', 'ret', 'Market Capitalization', 'turn','company_name','co_nic_code','nse_dummy','owner_gp_name'])\n"
     ]
    }
   ],
   "source": [
    "#Use Andy's Compustat data\n",
    "bse=\"BSE_.csv\"\n",
    "nse=\"NSE_.csv\"\n",
    "andy=\"andy_bse_merged.csv\"\n",
    "\n",
    "if ex==\"bse\":\n",
    "    crsp= pd.read_csv(bse,header=0,parse_dates=True)\n",
    "if ex==\"nse\":\n",
    "    crsp= pd.read_csv(nse,header=0,parse_dates=True)\n",
    "if ex==\"andy\":\n",
    "    crsp=pd.read_csv(andy, usecols=['permno', 'Date', 'ret', 'Market Capitalization', 'turn','company_name','co_nic_code','nse_dummy','owner_gp_name'])\n",
    "    crsp['nic_code_ini']=crsp['co_nic_code'].astype(str).str[:2]\n",
    "    exclude= pd.read_excel('andy_bse_lookup.xlsx',sheet_name=\"Sheet2\")\n",
    "    \n",
    "#Deals with Jayant Verma's monthly risk-free factors\n",
    "jayant= pd.read_csv('Jayant Verma Monthly.csv',usecols=['date','RF_'],parse_dates=True)\n",
    "jayant['date']=pd.to_datetime(jayant['date'],format=\"%Y-%m\") + MonthEnd(0)\n",
    "jayant=jayant.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "95583071-e4ba-4efc-8b88-c226ba19eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bse_only:\n",
    "    crsp=crsp[crsp['nse_dummy']==0]\n",
    "    \n",
    "#Remove the data which has data < 2000\n",
    "crsp['Date']= pd.to_datetime(crsp['Date']) + MonthEnd(0)\n",
    "crsp=crsp[crsp['Date'].dt.year >=2000]    \n",
    "\n",
    "crsp= crsp.rename(columns={'Date':'date'})\n",
    "\n",
    "cond= crsp.groupby('permno')['turn'].apply(lambda x: x.isna().any()).reset_index().rename(columns={'turn':'exc'})\n",
    "crsp= pd.merge(crsp,cond,on=\"permno\")\n",
    "#Exclude the firms which have NA in their turnover data\n",
    "crsp=crsp[crsp['exc']==False]\n",
    "\n",
    "#Convert the returns into a suitable format\n",
    "crsp['ret']= crsp['ret']/100\n",
    "\n",
    "if winsorize_ret:\n",
    "    crsp['ret']=crsp.groupby('date')['ret'].transform(lambda x: winsorize(x,limits=[0.01,0.01],inplace=True))\n",
    "\n",
    "# Final Calcultion through returns foramtion\n",
    "#fill in missing return with 0\n",
    "crsp['ret'] = crsp['ret'].fillna(0)\n",
    "\n",
    "# create log return for future usage\n",
    "crsp['logret'] = np.log(1+crsp['ret'])\n",
    "#crsp=crsp.dropna(subset='logret')\n",
    "\n",
    "crsp.columns=crsp.columns.str.strip()\n",
    "###########################################\n",
    "##Break here to describe the crsp dataframe\n",
    "###########################################\n",
    "#Remove the Government and financial firms for the analysis\n",
    "if rem_govt:\n",
    "    crsp= crsp[~crsp['owner_gp_name'].str.contains('Central')]\n",
    "    crsp= crsp[~crsp['owner_gp_name'].str.contains('State')]\n",
    "\n",
    "crsp['firm_threshold']= crsp.groupby(['date'])['permno'].transform(lambda x:x.nunique())\n",
    "crsp=crsp[crsp['firm_threshold']> 30]\n",
    "\n",
    "#Filter the Financial Firms with NIC_ini = 64,65,66\n",
    "if rem_fin:\n",
    "    crsp= crsp[~ crsp['nic_code_ini'].isin([64,65,66])]\n",
    "\n",
    "if penny_rem:\n",
    "    crsp=crsp[crsp['penny']==1]\n",
    "\n",
    "if market_decile:\n",
    "    crsp['market_decile']= crsp.groupby('date')['Market Capitalization'].transform(lambda x: pd.qcut(x, 10, labels=False)+1)\n",
    "    crsp= crsp[~crsp['market_decile'].isin([1])]\n",
    "\n",
    "if bottom:\n",
    "    crsp['threshold']=crsp.groupby('date')['Market Capitalization'].transform(lambda x: x.quantile(q))\n",
    "    crsp=crsp[crsp['Market Capitalization']> crsp['threshold']]\n",
    "if bottom_only:\n",
    "    crsp['threshold']=crsp.groupby('date')['Market Capitalization'].transform(lambda x: x.quantile(q))\n",
    "    crsp=crsp[crsp['Market Capitalization']< crsp['threshold']]\n",
    "    \n",
    "#Create baskets based on the turnover ratio\n",
    "crsp['basket']= crsp.groupby('date')['turn'].transform(lambda x: pd.qcut(x, basket, labels=False)+1)\n",
    "\n",
    "#Pre filtering Block  \n",
    "if liquidity==\"liquid\":\n",
    "    crsp=crsp[crsp['basket']==basket]\n",
    "    \n",
    "if liquidity==\"illiquid\":\n",
    "    crsp=crsp[crsp['basket']== 1]\n",
    "    \n",
    "if subsample:\n",
    "    crsp= crsp[crsp['date']>= sub_date ]\n",
    "\n",
    "crsp['ret_threshold']= crsp.groupby(['date'])['permno'].transform(lambda x:x.nunique())\n",
    "#Filter the firms which have a minimum of 10 returns in a given months\n",
    "crsp=crsp[crsp['ret_threshold']> 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1940f-af85-4be6-9139-b594aaff8507",
   "metadata": {},
   "source": [
    "## Momentum Analysis -> Post Initial Filtering, run the Momentum Strategy\n",
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "409009b5-daf2-4a49-a8dd-7f8b00948772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_rets(crsp_m,jayant,j=6,k=1,gap=False,rem_excess=False,sub_risk_free=False):\n",
    "    \"\"\"\n",
    "    Runs a momentum strategy in accordance with Jegadeesh and Titman (1993) paper titled\n",
    "    \"Returns to buying winners and selling losers\" for the given parameters.\n",
    "    \"\"\"\n",
    "    tmp_crsp = crsp_m[['permno','date','ret','logret']].sort_values(['permno','date']).set_index('date')\n",
    "\n",
    "    # Calculate Rolling Cumulative Return in the Formation Period\n",
    "    # By summing log returns over the J month formation period\n",
    "\n",
    "    umd = tmp_crsp.groupby(['permno'])['logret'].rolling(j, min_periods=j).sum().reset_index()\n",
    "    umd = umd.rename(columns={'logret':'sumlogret'})\n",
    "\n",
    "    # Then exp the sum log return to get compound return (not necessary) \n",
    "    umd['cumret']=np.exp(umd['sumlogret'])-1\n",
    "    #umd=umd[umd['cumret']!=0]\n",
    "\n",
    "    # For each date: assign ranking 1-10 based on cumret\n",
    "    # 1=lowest 10=highest cumret\n",
    "    umd=umd.dropna(axis=0, subset=['cumret'])\n",
    "\n",
    "\n",
    "    #Important Step to be followed\n",
    "\n",
    "    if rem_excess:\n",
    "\n",
    "        umd['thres']= umd.groupby('date')['cumret'].transform(lambda x:np.percentile(x,97.5))\n",
    "        umd=umd.set_index(['permno','date'])\n",
    "        aryan=umd[umd['cumret']<umd['thres']].groupby(level=1)['cumret'].transform(lambda x: pd.qcut(x,decile, labels=False)+1).to_frame(name=\"momr\").reset_index()\n",
    "\n",
    "        umd= pd.merge(umd,aryan,on=['date','permno'],how='outer')\n",
    "        umd['momr']= umd['momr'].astype(str).str[:-2]\n",
    "        umd=umd.reset_index()\n",
    "\n",
    "    else:\n",
    "        umd['momr']=umd.groupby('date')['cumret'].transform(lambda x: pd.qcut(x, decile, labels=False,duplicates='drop'))\n",
    "        # shift momr from 0-9 to 1-10\n",
    "        umd.momr=1+umd.momr\n",
    "\n",
    "    # First lineup date to month end date medate\n",
    "    # Then calculate hdate1 and hdate2 using medate\n",
    "    # Holding Period Length: K can be between 3 to 12 months\n",
    "    if gap:\n",
    "        g=1\n",
    "    else:\n",
    "        g=0\n",
    "    umd['form_date'] = umd['date']\n",
    "    umd['medate'] = umd['date']+MonthEnd(0)\n",
    "    umd['hdate1']=umd['medate']+MonthBegin(1+g)\n",
    "    umd['hdate2']=umd['medate']+MonthEnd(k+g)\n",
    "    umd = umd[['permno', 'form_date','momr','hdate1','hdate2']]\n",
    "\n",
    "    port = pd.merge(crsp_m[['permno','date','ret']], umd, on=['permno'], how='inner')\n",
    "    port = port[(port['hdate1']<=port['date']) & (port['date']<=port['hdate2'])]\n",
    "\n",
    "    # Rearrange the columns;\n",
    "    port = port[['permno','form_date', 'momr', 'hdate1','hdate2', 'date', 'ret']]\n",
    "\n",
    "    umd_port = port.groupby(['date','momr', 'form_date'])['ret'].mean().reset_index()\n",
    "\n",
    "    # Skip first two years of the sample \n",
    "    start_yr = umd_port.date.dt.year.min()+2\n",
    "    umd_port = umd_port.loc[umd_port.date.dt.year>=start_yr]\n",
    "    umd_port = umd_port.sort_values(by=['date','momr'])\n",
    "\n",
    "    # Create one return series per MOM group every month\n",
    "    ewret = umd_port.groupby(['momr','date'])['ret'].mean().reset_index()\n",
    "    ewstd = umd_port.groupby(['momr','date'])['ret'].std().reset_index()\n",
    "\n",
    "    ewret = ewret.rename(columns={'ret':'ewret'})\n",
    "    ewstd = ewstd.rename(columns={'ret':'ewretstd'})\n",
    "\n",
    "    ewretdf = pd.merge(ewret, ewstd, on=['date','momr'], how='inner')\n",
    "    ewretdf = ewretdf.sort_values(by=['momr', 'date'])\n",
    "\n",
    "\n",
    "    # Transpose portfolio layout to have columns as portfolio returns\n",
    "    ewret_t = ewretdf.pivot(index='date', columns='momr', values='ewret')\n",
    "\n",
    "    # Add prefix port in front of each column\n",
    "    ewret_t = ewret_t.add_prefix('port')\n",
    "    ewret_t = ewret_t.rename(columns={'port1':'losers', 'port'+ str(decile):'winners'})\n",
    "    ewret_t['long_short'] = ewret_t.winners - ewret_t.losers\n",
    "\n",
    "    #Extremely important step for decile formation\n",
    "    ewret_t=ewret_t.dropna(axis=0,subset=['losers','winners'])\n",
    "    # Compute Long-Short Portfolio Cumulative Returns\n",
    "\n",
    "    ewret_t= ewret_t.join(jayant,on='date',how='inner')\n",
    "    if sub_risk_free:\n",
    "        ewret_t['long_short']= ewret_t.long_short - ewret_t.RF_\n",
    "\n",
    "    ewret_t['cumret_winners']   = (1+ewret_t.winners).cumprod()-1\n",
    "    ewret_t['cumret_losers']    = (1+ewret_t.losers).cumprod()-1\n",
    "    ewret_t['cumret_long_short']= (1+ewret_t.long_short).cumprod()-1\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # Portfolio Summary Statistics  #\n",
    "    ################################# \n",
    "\n",
    "    # Mean \n",
    "    mom_mean = ewret_t[['winners', 'losers', 'long_short']].mean().to_frame().reset_index(drop=False)\n",
    "    mom_mean = mom_mean.rename(columns={'index': 'momr',0:'mean'})\n",
    "\n",
    "\n",
    "    mom_ser= pd.DataFrame(columns=['winners','losers','long_short'])\n",
    "    mom_ser['winners']=pd.Series(stats.sem(ewret_t['winners']))\n",
    "    mom_ser['losers']=pd.Series(stats.sem(ewret_t['losers']))\n",
    "    mom_ser['long_short']= pd.Series(stats.sem(ewret_t['long_short']))\n",
    "    mom_ser=mom_ser.T.reset_index(drop= False)\n",
    "    mom_ser=mom_ser.rename(columns={'index': 'momr', 0: 'std error'})\n",
    "\n",
    "    # T-Value and P-Value\n",
    "    t_losers = pd.Series(stats.ttest_1samp(ewret_t['losers'],0.0)).to_frame().T\n",
    "    t_winners = pd.Series(stats.ttest_1samp(ewret_t['winners'],0.0)).to_frame().T\n",
    "    t_long_short = pd.Series(stats.ttest_1samp(ewret_t['long_short'],0.0)).to_frame().T\n",
    "\n",
    "    t_losers['momr']='losers'\n",
    "    t_winners['momr']='winners'\n",
    "    t_long_short['momr']='long_short'\n",
    "\n",
    "    t_output =pd.concat([t_winners, t_losers, t_long_short])\\\n",
    "        .rename(columns={0:'t-stat', 1:'p-value'})\n",
    "\n",
    "     # Combine mean, t and p and format output\n",
    "    mom_output = pd.merge(mom_mean, t_output, on=['momr'], how='inner')\n",
    "    mom_output=pd.merge(mom_output, mom_ser, on='momr', how='inner')\n",
    "\n",
    "    mom_output['mean'] = mom_output['mean'].map('{:.2%}'.format)\n",
    "    mom_output['t-stat'] = mom_output['t-stat'].map('{:.2f}'.format)\n",
    "    mom_output['p-value'] = mom_output['p-value'].map('{:.3f}'.format)\n",
    "\n",
    "    return mom_output,ewret_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "461a5c16-7363-49e1-b317-8711d7cbb75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>momr</th>\n",
       "      <th>mean</th>\n",
       "      <th>t-stat</th>\n",
       "      <th>p-value</th>\n",
       "      <th>std error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>winners</td>\n",
       "      <td>2.21%</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>losers</td>\n",
       "      <td>1.89%</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.007858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>long_short</td>\n",
       "      <td>0.33%</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         momr   mean t-stat p-value  std error\n",
       "0     winners  2.21%   3.17   0.002   0.006972\n",
       "1      losers  1.89%   2.40   0.017   0.007858\n",
       "2  long_short  0.33%   1.69   0.092   0.001922"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j=1\n",
    "k=6\n",
    "mom,ewret_t= momentum_rets(crsp_m=crsp.copy(),jayant=jayant,j=j,k=k, gap=False,rem_excess=False,sub_risk_free=False)\n",
    "mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ce6267e5-5663-4390-937e-2e2fc64fa37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#Output Interface\n",
    "##################\n",
    "jk_table=False\n",
    "plot=False\n",
    "draw_plt =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "30843351-8c95-410e-ad10-61731b9a0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if jk_table:\n",
    "    loop=12\n",
    "    momentum=pd.DataFrame()\n",
    "    G=[False,True]\n",
    "    J=[1,3,6,9,12]\n",
    "    K=[1,3,6,9,12]\n",
    "    for gap in G:\n",
    "        for j in J:\n",
    "            for k in K:\n",
    "                try:\n",
    "\n",
    "                    mom,ewret_t= momentum_rets(crsp_m=crsp.copy(),j=j,k=k, gap=gap,rem_excess=False)\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "                else:\n",
    "                    mom.loc[:,\"G\"]=gap\n",
    "                    mom.loc[:,\"J\"]=j\n",
    "                    mom.loc[:,\"K\"]=k\n",
    "                    momentum=pd.concat([momentum,mom],axis=0)\n",
    "    momentum.to_csv('mom_op_'+str(loop) +\".csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "729221cc-1221-44cb-95ed-fc55e593c0ed",
   "metadata": {},
   "source": [
    "loop= 6\n",
    "momentum=pd.DataFrame()\n",
    "G=[False,True]\n",
    "for gap in G:\n",
    "    for j in range(1,7):\n",
    "        for k in range(1,7):\n",
    "            mom,ewret_t= momentum_rets(crsp_m=crsp.copy(),j=j,k=k, gap=gap,rem_excess=False)\n",
    "            mom.loc[:,\"G\"]=gap\n",
    "            mom.loc[:,\"J\"]=j\n",
    "            mom.loc[:,\"K\"]=k\n",
    "            momentum=pd.concat([momentum,mom],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "188bdf36-9cfa-4478-95f1-e7eba283cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawdown(return_series: pd.Series,rescale_fac= False):\n",
    "    \"\"\"Takes a time series of asset returns.\n",
    "       returns a DataFrame with columns for\n",
    "       the wealth index, \n",
    "       the previous peaks, and \n",
    "       the percentage drawdown\n",
    "    \"\"\"\n",
    "    wealth_index = 1000*(1+return_series).cumprod()\n",
    "    if rescale_fac:\n",
    "        wealth_index= -1* wealth_index\n",
    "    previous_peaks = wealth_index.cummax()\n",
    "    drawdowns = (wealth_index - previous_peaks)/previous_peaks\n",
    "    return pd.DataFrame({\"Wealth\": wealth_index, \n",
    "                         \"Previous Peak\": previous_peaks, \n",
    "                         \"Drawdown\": drawdowns})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "06f0f443-4a5b-4f04-954c-532062f08e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if draw_plt:\n",
    "    draw= drawdown(ewret_t['long_short'],rescale_fac=False).Drawdown\n",
    "    draw.plot(figsize=(12,9),color='r',style=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "15ac5565-f55f-4daa-a81e-de507343681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot:\n",
    "    ewret_t1['cumret_long_short'].plot(figsize=(12,6),style=\"--\",color=\"red\",secondary_y=True)\n",
    "    ewret_t0['cumret_long_short'].plot(figsize=(12,6),style=\"--\",color=\"black\")\n",
    "    ewret_t_['cumret_long_short'].plot(figsize=(12,6),style=\"--\",color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81494826-908f-4cd9-985d-e21c9ba8bcb8",
   "metadata": {},
   "source": [
    "# Notes and Discussions for reference of the programmer\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c5630-7109-4d45-926d-11152aff3eb9",
   "metadata": {},
   "source": [
    "## Output File 4\n",
    "1. BSE price momentum based on JT 93 remove bottom 5% Market Cap\n",
    "2. BSE~NSE price momentum based on JT 93 remove bottom 5% Market Cap\n",
    "3. BSE price momentum based on JT 93 remove bottom 5% Market Cap most liquid decile\n",
    "4. BSE price momentum based on JT 93 remove bottom 5% Market Cap least liquid decile\n",
    "5. BSE~NSE price momentum based on JT 93 remove bottom 5% Market Cap least liquid decile\n",
    "6. BSE~NSE price momentum based on JT 93 remove bottom 5% Market Cap most liquid decile\n",
    "7. Penny stocks on bottom 25%  Market Cap based on JT 93\n",
    "8. BSE~NSE price momentum based on JT 93\n",
    "9. BSE price momentum based on JT 93 remove bottom 5% Market Cap most liquid decile Long term returns\n",
    "10. BSE price momentum based on JT 93 remove bottom 5% Market Cap Long term returns\n",
    "11. BSE price momentum based on JT 93 remove bottom 5% Market Cap least liquid decile Long term returns\n",
    "12. Penny stocks on bottom 10%  Market Cap based on JT 93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9272c-7e8e-4c6f-9203-58b74ca44762",
   "metadata": {},
   "source": [
    "## Output File 3\n",
    "\n",
    "1. BSE price momentum without filtering\n",
    "2. NSE price momentum without filtering\n",
    "3. BSE~NSE price momemtum without filteringe\n",
    "4. BSE price momentum JK Table\n",
    "5. BSE~NSE price momentum JK Table\n",
    "6. NSE price momentum JK Table\n",
    "7. NSE price momentum with Market filter at 10%\n",
    "8. BSE price momentum with Market filter at 10%\n",
    "9. BSE~NSE price momentum with Market filter at 10%\n",
    "10. BSE price momentum JK Table from 2000\n",
    "11. BSE~NSE price momentum JK Table from 2000\n",
    "12. NSE price momentum JK Table from 2000\n",
    "13. BSE price momentum with Market filter at 10% from 2000\n",
    "14. BSE~NSE price momentum with Market filter at 10% from 2000\n",
    "15. NSE price momentum with Market filter at 10% from 2000\n",
    "16. BSE price momentum on penny stocks below Rs. 10\n",
    "17. BSE~NSE price momentum on penny stocks below Rs. 10\n",
    "18. NSE price momentum on penny stocks below Rs. 10\n",
    "\n",
    "## Output File 2\n",
    "1. Unconditional without any filtering wins=0.01, remove bottom decile of Market Cap, remove excess returns decile\n",
    "2. Unconditional without any filtering wins=0.01\n",
    "3. Unconditional without any filtering wins=0.01, remove bottom 10% Market Cap by number\n",
    "4. -> Unconditional without any filtering wins=0.01, remove bottom 25% Market Cap by number\n",
    "5. Unconditional without any filtering wins=0.01, remove penny stocks under Rs 10\n",
    "6. -> Most Liquid Decile wins=0.01, remove bottom decile of Market Cap\n",
    "7. -> Least Liquid Decile wins=0.01, don't use cumret in the bottom decile\n",
    "8. Penny Stocks in Market Cap bottom decile wins=0.01, don't use cumret in the bottom decile\n",
    "9. Penny Stocks in Market Cap bottom decile wins=0.01\n",
    "10. Penny Stocks in Market Cap bottom quintile \n",
    "11. Penny Stocks in Market Cap bottom quintile, don't use cumret in the bottom decile\n",
    "12. Penny Stocks in Market Cap bottom quintile  wins=0.01\n",
    "13. Penny Stocks in Market Cap bottom quintile wins=0.01 , don't use cumret in the bottom decile\n",
    "\n",
    "## Output File 1\n",
    "\n",
    "1. Unconditional without any filtering\n",
    "2. Decile is liquid without any filtering\n",
    "3. Decile is not liquid without any filtering -> Output Found with corrections\n",
    "4. Unconditional with penny remove at 10\n",
    "5. Decile is liquid with penny remove at 10\n",
    "6. Decile is not liquid with penny remove at 10 -> Output by removing outliers\n",
    "7. Unconditional with penny remove at 30\n",
    "8. Liquid with penny remove at 30\n",
    "9. Not liquid with penny remove at 30 -> Output by removing outliers\n",
    "10. Unconditional with marketcap remove bottom 10\n",
    "11. Liquid remove bottom 10 marketcap\n",
    "12. Not liquid with marketcap remove bottom 10 marketcap -> Output Found with corrections\n",
    "13. Unconditional with remove marketcap bottom 25\n",
    "14. Liquid with remove marketcap bottom 25\n",
    "15. Not liquid with marketcap remove bottom 25-> Output Found with corrections\n",
    "16. Unconditional with marketcap remove 10 and penny 10\n",
    "17. Liquid with marketcap remove 10 and penny 10\n",
    "18. Not Liquid with marketcap remove 10 and penny 10 -> No Output as deciles not forming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
